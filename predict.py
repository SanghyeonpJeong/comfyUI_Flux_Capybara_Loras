import torch
import os
from cog import BasePredictor, Input, Path
from diffusers import FluxPipeline
# ğŸŒŸ (ì‚­ì œ) snapshot_download import ì‚­ì œ

# ğŸŒŸ (ìˆ˜ì •) ê¸°ë°˜ ì´ë¯¸ì§€(fofr/flux-dev)ê°€ ëª¨ë¸ì„ ì €ì¥í•œ ê²½ë¡œ
# (ì´ ê²½ë¡œëŠ” fofr/flux-devì˜ cog.yamlì„ ì°¸ì¡°í•˜ì—¬ í™•ì¸í–ˆìŠµë‹ˆë‹¤)
MODEL_ID = "black-forest-labs/FLUX.1-dev"
LORA_PATH = "/src/loras/Flux_Capybara_v1.safetensors"

class Predictor(BasePredictor):
    def setup(self):
        """ğŸŒŸ (ìˆ˜ì •) ëŸ°íƒ€ì„ ë‹¤ìš´ë¡œë“œ 'ì‚­ì œ'. ê¸°ë°˜ ì´ë¯¸ì§€ì˜ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. ğŸŒŸ"""
        print("Booting... Loading FLUX.1-dev pipeline from base image...")
        
        # 1. ëŸ°íƒ€ì„ì— Gated Model ë‹¤ìš´ë¡œë“œ (ì‚­ì œë¨)
        # (ê¸°ë°˜ ì´ë¯¸ì§€ì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ)
        
        # 2. ë¡œì»¬ ìºì‹œ ê²½ë¡œì—ì„œ ëª¨ë¸ ë¡œë“œ
        # (DiffusersëŠ” MODEL_IDë¥¼ ë³´ê³ , ì´ë¯¸ ìºì‹œëœ ê²ƒì„ í™•ì¸í•˜ê³  ì¦‰ì‹œ ë¡œë“œí•©ë‹ˆë‹¤)
        self.pipe = FluxPipeline.from_pretrained(
            MODEL_ID, # ğŸŒŸ í† í° ì—†ì´ IDë§Œ ì „ë‹¬
            torch_dtype=torch.bfloat16
        )
        
        # 3. VRAM ì ˆì•½ì„ ìœ„í•´ CPU ì˜¤í”„ë¡œë“œ
        self.pipe.enable_model_cpu_offload()
        
        # 4. LoRA ë¡œë“œ (í•„ìˆ˜!)
        # (ì´ ë¶€ë¶„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ LoRAë¥¼ ì ìš©í•©ë‹ˆë‹¤)
        self.pipe.load_lora_weights(LORA_PATH)
        print(f"LoRA loaded from {LORA_PATH}")

        print("FluxPipeline loaded successfully. Booting complete.")

    def predict(
        self,
        prompt: str = Input(description="Prompt for the model."),
        height: int = Input(description="Height of the image.", default=1024),
        width: int = Input(description="Width of the image.", default=1024),
        num_inference_steps: int = Input(description="Number of inference steps.", default=50),
        guidance_scale: float = Input(description="Guidance scale.", default=3.5)
    ) -> Path: 
        """í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        # ğŸŒŸ (ìˆ˜ì •) LoRAë¥¼ ì ìš©í–ˆìœ¼ë¯€ë¡œ, predict ì‹œ lora_scaleì„ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # (ë‹¨, LoRA ë¡œë“œ ë°©ì‹ì— ë”°ë¼ ì´ ì½”ë“œëŠ” ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
        image = self.pipe(
            prompt=prompt,
            height=height,
            width=width,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps,
            generator=torch.Generator("cpu").manual_seed(0)
            # cross_attention_kwargs={"scale": 0.93} # LoRA ìŠ¤ì¼€ì¼ ì˜ˆì‹œ
        ).images[0]
        
        output_path = "/tmp/output.png"
        image.save(output_path)
        return Path(output_path)